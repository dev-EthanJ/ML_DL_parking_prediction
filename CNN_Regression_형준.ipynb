{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHpzw-m6wc_s",
        "outputId": "efbc12c4-8db2-48f4-a0a9-59a2bb87102c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/PD_ML/project2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8W4d-vrwd0s",
        "outputId": "adab4937-e1db-4c0c-8f47-95e2ae26f4af"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PD_ML/project2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 글꼴깨짐 방지\n",
        "import matplotlib\n",
        "import matplotlib.font_manager as fm\n",
        "\n",
        "import warnings\n",
        "\n",
        "# 경고 메시지를 무시하고 숨기거나\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "VLqbP8PRwgPj"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r22-_Vzlw68x",
        "outputId": "175cee38-ca27-4409-e0aa-f8d07947799b"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 5 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "dH8VJfKqwnzA"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(df):\n",
        "    # 오류 단지코드가 존재하는 행들을  사전에 제거\n",
        "    df_error =  ['C1095', 'C2051', 'C1218', 'C1894', 'C2483', 'C1502', 'C1988']\n",
        "    #df_error =  ['C2335', 'C1327']\n",
        "    df = df[~df['단지코드'].isin(df_error)].reset_index(drop=True)\n",
        "    df.rename(columns = {'도보 10분거리 내 지하철역 수(환승노선 수 반영)':'지하철','도보 10분거리 내 버스정류장 수':'버스'},inplace=True)\n",
        "    df.drop(columns=['임대보증금','임대료','자격유형','임대건물구분'],axis = 1,inplace=True)\n",
        "    지역_비율 = (df.groupby(['지역'])['총세대수'].count())/(df.groupby(['지역'])['총세대수'].count().sum())*100\n",
        "    지역_비율=지역_비율.reset_index(name='지역_비율')\n",
        "    공급유형_비율 = (df.groupby(['공급유형'])['총세대수'].count())/(df.groupby(['공급유형'])['총세대수'].count().sum())*100\n",
        "    공급유형_비율=공급유형_비율.reset_index(name='공급유형_비율')\n",
        "    df = pd.merge(df,지역_비율, on='지역')\n",
        "    df = pd.merge(df,공급유형_비율, on='공급유형')\n",
        "    df.drop(columns=['지역','공급유형','단지코드'],axis = 1,inplace=True)\n",
        "    df=df.dropna(axis=0)\n",
        "    df = df[['총세대수', '전용면적', '전용면적별세대수', '공가수', '지하철', '버스', '단지내주차면수', '공급유형_비율',\n",
        "       '지역_비율', '등록차량수']]\n",
        "    return df"
      ],
      "metadata": {
        "id": "a7c8PknawrfG"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = preprocessing(dataset)"
      ],
      "metadata": {
        "id": "-BDCzxeHws63"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# import 1D convolutional layer\n",
        "from torch.nn import Conv1d\n",
        "\n",
        "# import max pooling layer\n",
        "from torch.nn import MaxPool1d\n",
        "\n",
        "# import the flatten layer \n",
        "from torch.nn import Flatten\n",
        "\n",
        "# import linear layer\n",
        "from torch.nn import Linear\n",
        "\n",
        "# import activation function (ReLU)\n",
        "from torch.nn.functional import relu\n",
        "\n",
        "# import libraries required for working with dataset from pytorch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "J_3F3IuBw0m3"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defined model named as CnnRegressor and\n",
        "# this model should be the subclass of torch.nn.Module \n",
        "class CnnRegressor(torch.nn.Module):\n",
        "  # defined the initialization method\n",
        "  def __init__(self, batch_size, inputs, outputs):\n",
        "    # initialization of the superclass\n",
        "    super(CnnRegressor, self).__init__()\n",
        "    # store the parameters\n",
        "    self.batch_size = batch_size\n",
        "    self.inputs = inputs\n",
        "    self.outputs = outputs\n",
        "    # define the input layer\n",
        "    self.input_layer = Conv1d(inputs, batch_size, 1, stride = 1)\n",
        "   \n",
        "    # define max pooling layer\n",
        "    self.max_pooling_layer = MaxPool1d(1)\n",
        "\n",
        "    # define other convolutional layers\n",
        "    self.conv_layer1 = Conv1d(batch_size, 128, 1, stride = 3)\n",
        "    self.conv_layer2 = Conv1d(128, 256, 1, stride = 3)\n",
        "    self.conv_layer3 = Conv1d(256, 512, 1, stride = 3)\n",
        "\n",
        "    # define the flatten layer\n",
        "    self.flatten_layer = Flatten()\n",
        "\n",
        "    # define the linear layer\n",
        "    self.linear_layer = Linear(512, 128)\n",
        "\n",
        "    # define the output layer\n",
        "    self.output_layer = Linear(128, outputs)\n",
        "\n",
        "  # define the method to feed the inputs to the model\n",
        "  def feed(self, input):\n",
        "    # input is reshaped to the 1D array and fed into the input layer\n",
        "    input = input.reshape((self.batch_size, self.inputs, 1))\n",
        "\n",
        "    # ReLU is applied on the output of input layer\n",
        "    output = relu(self.input_layer(input))\n",
        "\n",
        "    # max pooling is applied and then Convolutions are done with ReLU\n",
        "    output = self.max_pooling_layer(output)\n",
        "    output = relu(self.conv_layer1(output))\n",
        "\n",
        "    output = self.max_pooling_layer(output)\n",
        "    output = relu(self.conv_layer2(output))\n",
        "\n",
        "    output = self.max_pooling_layer(output)\n",
        "    output = relu(self.conv_layer3(output))\n",
        "\n",
        "    # flatten layer is applied\n",
        "    output = self.flatten_layer(output)\n",
        "\n",
        "    # linear layer and ReLu is applied\n",
        "    output = relu(self.linear_layer(output))\n",
        "\n",
        "    # finally, output layer is applied\n",
        "    output = self.output_layer(output)\n",
        "    return output"
      ],
      "metadata": {
        "id": "OVyKwZg960ZB"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import SGD for optimizer\n",
        "from torch.optim import SGD\n",
        "\n",
        "# import Adam for optimizer\n",
        "from torch.optim import Adam\n",
        "\n",
        "# to measure the performance import L1Loss\n",
        "from torch.nn import L1Loss\n",
        "\n",
        "# install pytorch's ignite and then import R2 score package\n",
        "!pip install pytorch-ignite\n",
        "from ignite.contrib.metrics.regression.r2_score import R2Score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlCrumrRxboK",
        "outputId": "ce935d58-9cd5-4c9e-9513-5e5a7f749644"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.iloc[:, 1:-1].to_numpy()\n",
        "y = dataset.iloc[:,-1].to_numpy()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Q28IN275xkcz"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the batch size  \n",
        "batch_size = 100\n",
        "model = CnnRegressor(batch_size, X.shape[1], 1)\n",
        "\n",
        "# we are using GPU so we have to set the model for that\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRpX71Wvxc-I",
        "outputId": "6bc481a6-100c-4f03-adae-166ef70b4532"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CnnRegressor(\n",
              "  (input_layer): Conv1d(8, 100, kernel_size=(1,), stride=(1,))\n",
              "  (max_pooling_layer): MaxPool1d(kernel_size=1, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv_layer1): Conv1d(100, 128, kernel_size=(1,), stride=(3,))\n",
              "  (conv_layer2): Conv1d(128, 256, kernel_size=(1,), stride=(3,))\n",
              "  (conv_layer3): Conv1d(256, 512, kernel_size=(1,), stride=(3,))\n",
              "  (flatten_layer): Flatten(start_dim=1, end_dim=-1)\n",
              "  (linear_layer): Linear(in_features=512, out_features=128, bias=True)\n",
              "  (output_layer): Linear(in_features=128, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_loss(model, dataset, train = False, optimizer = None):\n",
        "  # first calculated for the batches and at the end get the average\n",
        "  performance = L1Loss()\n",
        "  score_metric = R2Score()\n",
        "\n",
        "  avg_loss = 0\n",
        "  avg_score = 0\n",
        "  count = 0\n",
        "\n",
        "  for input, output in iter(dataset):\n",
        "    # get predictions of the model for training set\n",
        "    predictions = model.feed(input)\n",
        "\n",
        "    # calculate loss of the model\n",
        "    loss = performance(predictions, output)\n",
        "\n",
        "    # compute the R2 score\n",
        "    score_metric.update([predictions, output])\n",
        "    score = score_metric.compute()\n",
        "\n",
        "    if(train):\n",
        "      # clear the errors\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # compute the gradients for optimizer\n",
        "      loss.backward()\n",
        "\n",
        "      # use optimizer in order to update parameters\n",
        "      # of the model based on gradients\n",
        "      optimizer.step()\n",
        "\n",
        "    # store the loss and update values\n",
        "    avg_loss += loss.item()\n",
        "    avg_score += score\n",
        "    count += 1\n",
        "\n",
        "  return avg_loss/count, avg_score/count"
      ],
      "metadata": {
        "id": "xETYhux-xftz"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the number of epochs\n",
        "epochs = 100\n",
        "\n",
        "# define the performance measure and optimizer\n",
        "# optimizer = SGD( model.parameters(), lr= 1e-5)\n",
        "optimizer = Adam(model.parameters())\n",
        "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100, eta_min=0)\n",
        "\n",
        "# to process with GPU, training set is converted into torch variable\n",
        "inputs = torch.from_numpy(X_train).cuda().float()\n",
        "outputs = torch.from_numpy(y_train.reshape(y_train.shape[0],1)).cuda().float()\n",
        "\n",
        "# create the DataLoader instance to work with batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle = True, drop_last = True)\n",
        "\n",
        "\n",
        "loss_list = []\n",
        "r2_list = []\n",
        "\n",
        "# loop for number of epochs and calculate average loss\n",
        "for epoch in range(epochs):\n",
        "   # model is cycled through the batches\n",
        "  avg_loss, avg_r2_score = model_loss(model, loader, train = True, optimizer = optimizer)\n",
        "  print(\"Epoch \" + str(epoch + 1) + \":\\n\\tLoss = \" + str(avg_loss) + \"\\n\\tR^2 Score = \" + str(avg_r2_score))\n",
        "  loss_list.append(avg_loss)\n",
        "  r2_list.append(avg_r2_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPuUD12ax3BM",
        "outputId": "84e0c64a-0142-497c-d10d-22cfe1f2ed7f"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "\tLoss = 527.1439557756696\n",
            "\tR^2 Score = -1.9333971197389548\n",
            "Epoch 2:\n",
            "\tLoss = 208.4740745907738\n",
            "\tR^2 Score = 0.29685054278256284\n",
            "Epoch 3:\n",
            "\tLoss = 163.07098606654577\n",
            "\tR^2 Score = 0.6650515584877116\n",
            "Epoch 4:\n",
            "\tLoss = 158.79049682617188\n",
            "\tR^2 Score = 0.7030836419850217\n",
            "Epoch 5:\n",
            "\tLoss = 152.8808121454148\n",
            "\tR^2 Score = 0.7245779216178352\n",
            "Epoch 6:\n",
            "\tLoss = 151.20064835321335\n",
            "\tR^2 Score = 0.7020592910925456\n",
            "Epoch 7:\n",
            "\tLoss = 150.58685775030227\n",
            "\tR^2 Score = 0.717131810625307\n",
            "Epoch 8:\n",
            "\tLoss = 146.36517733619326\n",
            "\tR^2 Score = 0.7381267059874168\n",
            "Epoch 9:\n",
            "\tLoss = 142.2853230067662\n",
            "\tR^2 Score = 0.7475855293857119\n",
            "Epoch 10:\n",
            "\tLoss = 140.9726315452939\n",
            "\tR^2 Score = 0.7601686590166863\n",
            "Epoch 11:\n",
            "\tLoss = 138.97242300851005\n",
            "\tR^2 Score = 0.7688401921877203\n",
            "Epoch 12:\n",
            "\tLoss = 140.67366718110583\n",
            "\tR^2 Score = 0.7704357546693856\n",
            "Epoch 13:\n",
            "\tLoss = 136.75274294898622\n",
            "\tR^2 Score = 0.7692644372766376\n",
            "Epoch 14:\n",
            "\tLoss = 143.2701132638114\n",
            "\tR^2 Score = 0.7514241177994969\n",
            "Epoch 15:\n",
            "\tLoss = 138.268672761463\n",
            "\tR^2 Score = 0.7535445797053324\n",
            "Epoch 16:\n",
            "\tLoss = 134.84973725818452\n",
            "\tR^2 Score = 0.7733125549699589\n",
            "Epoch 17:\n",
            "\tLoss = 132.53753371465774\n",
            "\tR^2 Score = 0.792522799556342\n",
            "Epoch 18:\n",
            "\tLoss = 135.59285736083984\n",
            "\tR^2 Score = 0.7925669064397196\n",
            "Epoch 19:\n",
            "\tLoss = 133.85884820847284\n",
            "\tR^2 Score = 0.7467290780330379\n",
            "Epoch 20:\n",
            "\tLoss = 129.75354548863\n",
            "\tR^2 Score = 0.7777887772433368\n",
            "Epoch 21:\n",
            "\tLoss = 128.69720713297525\n",
            "\tR^2 Score = 0.7831963732678825\n",
            "Epoch 22:\n",
            "\tLoss = 130.08678181966147\n",
            "\tR^2 Score = 0.7818769215876364\n",
            "Epoch 23:\n",
            "\tLoss = 125.67791602725075\n",
            "\tR^2 Score = 0.7936858053866787\n",
            "Epoch 24:\n",
            "\tLoss = 125.23901003882999\n",
            "\tR^2 Score = 0.8004016330709735\n",
            "Epoch 25:\n",
            "\tLoss = 125.20296914236886\n",
            "\tR^2 Score = 0.8033122242434545\n",
            "Epoch 26:\n",
            "\tLoss = 124.99301220121838\n",
            "\tR^2 Score = 0.7996006946962223\n",
            "Epoch 27:\n",
            "\tLoss = 126.30214618501209\n",
            "\tR^2 Score = 0.811336127544139\n",
            "Epoch 28:\n",
            "\tLoss = 125.40879967099144\n",
            "\tR^2 Score = 0.7899624666614167\n",
            "Epoch 29:\n",
            "\tLoss = 126.14280373709542\n",
            "\tR^2 Score = 0.8102296758053994\n",
            "Epoch 30:\n",
            "\tLoss = 127.64297812325614\n",
            "\tR^2 Score = 0.7925144934160239\n",
            "Epoch 31:\n",
            "\tLoss = 125.42643410818917\n",
            "\tR^2 Score = 0.7943725681559922\n",
            "Epoch 32:\n",
            "\tLoss = 121.66136569068546\n",
            "\tR^2 Score = 0.8080994109693089\n",
            "Epoch 33:\n",
            "\tLoss = 121.08188992454892\n",
            "\tR^2 Score = 0.8065614958296374\n",
            "Epoch 34:\n",
            "\tLoss = 119.93089948381696\n",
            "\tR^2 Score = 0.8082313927061022\n",
            "Epoch 35:\n",
            "\tLoss = 119.58959779285249\n",
            "\tR^2 Score = 0.8175317289749158\n",
            "Epoch 36:\n",
            "\tLoss = 119.78980800083706\n",
            "\tR^2 Score = 0.8162177577475097\n",
            "Epoch 37:\n",
            "\tLoss = 118.5920893351237\n",
            "\tR^2 Score = 0.8290152327690217\n",
            "Epoch 38:\n",
            "\tLoss = 117.84567042759487\n",
            "\tR^2 Score = 0.8156615059212161\n",
            "Epoch 39:\n",
            "\tLoss = 117.75923374720982\n",
            "\tR^2 Score = 0.8271769544313844\n",
            "Epoch 40:\n",
            "\tLoss = 117.4295912243071\n",
            "\tR^2 Score = 0.8199594349227469\n",
            "Epoch 41:\n",
            "\tLoss = 116.48531196230934\n",
            "\tR^2 Score = 0.8230300555598934\n",
            "Epoch 42:\n",
            "\tLoss = 116.88091641380673\n",
            "\tR^2 Score = 0.8240669256366184\n",
            "Epoch 43:\n",
            "\tLoss = 118.34115164620536\n",
            "\tR^2 Score = 0.8236934142462627\n",
            "Epoch 44:\n",
            "\tLoss = 115.80879465738933\n",
            "\tR^2 Score = 0.8356694507499457\n",
            "Epoch 45:\n",
            "\tLoss = 114.61570776076545\n",
            "\tR^2 Score = 0.8256476151533879\n",
            "Epoch 46:\n",
            "\tLoss = 116.90908522832962\n",
            "\tR^2 Score = 0.8322242926504947\n",
            "Epoch 47:\n",
            "\tLoss = 115.71435147240048\n",
            "\tR^2 Score = 0.8185772184636347\n",
            "Epoch 48:\n",
            "\tLoss = 115.49273209344773\n",
            "\tR^2 Score = 0.8113775256716655\n",
            "Epoch 49:\n",
            "\tLoss = 116.28214300246466\n",
            "\tR^2 Score = 0.8261242840420018\n",
            "Epoch 50:\n",
            "\tLoss = 114.8428217569987\n",
            "\tR^2 Score = 0.8328417554438355\n",
            "Epoch 51:\n",
            "\tLoss = 113.27453140985398\n",
            "\tR^2 Score = 0.8220480689679481\n",
            "Epoch 52:\n",
            "\tLoss = 114.30664571126302\n",
            "\tR^2 Score = 0.8233217168792009\n",
            "Epoch 53:\n",
            "\tLoss = 116.04335058303107\n",
            "\tR^2 Score = 0.8448042472866136\n",
            "Epoch 54:\n",
            "\tLoss = 114.98886980329242\n",
            "\tR^2 Score = 0.816068041089265\n",
            "Epoch 55:\n",
            "\tLoss = 114.44813791910808\n",
            "\tR^2 Score = 0.8356983311507891\n",
            "Epoch 56:\n",
            "\tLoss = 111.50028955368768\n",
            "\tR^2 Score = 0.8306149369551282\n",
            "Epoch 57:\n",
            "\tLoss = 113.44654337565105\n",
            "\tR^2 Score = 0.8310960865845732\n",
            "Epoch 58:\n",
            "\tLoss = 113.93401336669922\n",
            "\tR^2 Score = 0.8385706615583985\n",
            "Epoch 59:\n",
            "\tLoss = 116.93702625093006\n",
            "\tR^2 Score = 0.8235606689507209\n",
            "Epoch 60:\n",
            "\tLoss = 112.69285038539341\n",
            "\tR^2 Score = 0.8327426323299175\n",
            "Epoch 61:\n",
            "\tLoss = 111.2927983601888\n",
            "\tR^2 Score = 0.8150120350726313\n",
            "Epoch 62:\n",
            "\tLoss = 110.91051010858445\n",
            "\tR^2 Score = 0.8305396753514364\n",
            "Epoch 63:\n",
            "\tLoss = 112.433593023391\n",
            "\tR^2 Score = 0.8488056584898407\n",
            "Epoch 64:\n",
            "\tLoss = 111.33830878848121\n",
            "\tR^2 Score = 0.8432224641200627\n",
            "Epoch 65:\n",
            "\tLoss = 110.97942679268974\n",
            "\tR^2 Score = 0.8245242382626276\n",
            "Epoch 66:\n",
            "\tLoss = 111.0534900483631\n",
            "\tR^2 Score = 0.8251675937518319\n",
            "Epoch 67:\n",
            "\tLoss = 110.09733508882069\n",
            "\tR^2 Score = 0.827842791542634\n",
            "Epoch 68:\n",
            "\tLoss = 112.39590672084263\n",
            "\tR^2 Score = 0.8275634474382287\n",
            "Epoch 69:\n",
            "\tLoss = 109.01606023879279\n",
            "\tR^2 Score = 0.8282389594994684\n",
            "Epoch 70:\n",
            "\tLoss = 110.36917259579613\n",
            "\tR^2 Score = 0.8373969816427467\n",
            "Epoch 71:\n",
            "\tLoss = 112.5521254766555\n",
            "\tR^2 Score = 0.846795537895674\n",
            "Epoch 72:\n",
            "\tLoss = 113.03744070870536\n",
            "\tR^2 Score = 0.8357510182507145\n",
            "Epoch 73:\n",
            "\tLoss = 111.8373765491304\n",
            "\tR^2 Score = 0.8334054351469333\n",
            "Epoch 74:\n",
            "\tLoss = 109.04365939185733\n",
            "\tR^2 Score = 0.8471143522167421\n",
            "Epoch 75:\n",
            "\tLoss = 108.47526441301618\n",
            "\tR^2 Score = 0.8457392401861994\n",
            "Epoch 76:\n",
            "\tLoss = 108.08990369524274\n",
            "\tR^2 Score = 0.8298036339675438\n",
            "Epoch 77:\n",
            "\tLoss = 109.68718646821522\n",
            "\tR^2 Score = 0.8259481781916143\n",
            "Epoch 78:\n",
            "\tLoss = 107.44233921595982\n",
            "\tR^2 Score = 0.827721449889604\n",
            "Epoch 79:\n",
            "\tLoss = 109.76974124000186\n",
            "\tR^2 Score = 0.8381283651811101\n",
            "Epoch 80:\n",
            "\tLoss = 107.98272305443173\n",
            "\tR^2 Score = 0.8379721368072953\n",
            "Epoch 81:\n",
            "\tLoss = 107.93918209984189\n",
            "\tR^2 Score = 0.8437935406121888\n",
            "Epoch 82:\n",
            "\tLoss = 108.77825927734375\n",
            "\tR^2 Score = 0.8308844043375901\n",
            "Epoch 83:\n",
            "\tLoss = 107.95897238595145\n",
            "\tR^2 Score = 0.8443131115509628\n",
            "Epoch 84:\n",
            "\tLoss = 108.14769926525298\n",
            "\tR^2 Score = 0.841602063869769\n",
            "Epoch 85:\n",
            "\tLoss = 108.43114725748698\n",
            "\tR^2 Score = 0.8436446551673743\n",
            "Epoch 86:\n",
            "\tLoss = 106.47928219749814\n",
            "\tR^2 Score = 0.8508320741787556\n",
            "Epoch 87:\n",
            "\tLoss = 107.28916567847843\n",
            "\tR^2 Score = 0.8459851664206008\n",
            "Epoch 88:\n",
            "\tLoss = 108.19735899425689\n",
            "\tR^2 Score = 0.8413534652983207\n",
            "Epoch 89:\n",
            "\tLoss = 111.39821225120907\n",
            "\tR^2 Score = 0.825704096006217\n",
            "Epoch 90:\n",
            "\tLoss = 107.68991016206287\n",
            "\tR^2 Score = 0.8372158481397136\n",
            "Epoch 91:\n",
            "\tLoss = 110.28099931989398\n",
            "\tR^2 Score = 0.8308491444422328\n",
            "Epoch 92:\n",
            "\tLoss = 108.9368889218285\n",
            "\tR^2 Score = 0.8280557326505705\n",
            "Epoch 93:\n",
            "\tLoss = 107.50007484072731\n",
            "\tR^2 Score = 0.8449853230624288\n",
            "Epoch 94:\n",
            "\tLoss = 108.07398260207404\n",
            "\tR^2 Score = 0.836828325691763\n",
            "Epoch 95:\n",
            "\tLoss = 110.0716062273298\n",
            "\tR^2 Score = 0.8341184660102927\n",
            "Epoch 96:\n",
            "\tLoss = 106.7661866687593\n",
            "\tR^2 Score = 0.8514826478720879\n",
            "Epoch 97:\n",
            "\tLoss = 105.96491096133278\n",
            "\tR^2 Score = 0.8486988828204765\n",
            "Epoch 98:\n",
            "\tLoss = 109.53280566987537\n",
            "\tR^2 Score = 0.8369851767889371\n",
            "Epoch 99:\n",
            "\tLoss = 106.73000299362909\n",
            "\tR^2 Score = 0.8344371411350295\n",
            "Epoch 100:\n",
            "\tLoss = 104.6860845656622\n",
            "\tR^2 Score = 0.8423737058708202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(),'conv_reg.h')"
      ],
      "metadata": {
        "id": "rmC948zux6FC"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to process with GPU, testing set is converted into torch variable\n",
        "inputs = torch.from_numpy(X_test).cuda().float()\n",
        "outputs = torch.from_numpy(y_test.reshape(y_test.shape[0],1)).cuda().float()\n",
        "\n",
        "# create the DataLoader instance to work with batches\n",
        "tensor = TensorDataset(inputs, outputs)\n",
        "loader = DataLoader(tensor, batch_size, shuffle = True, drop_last = True)\n",
        "\n",
        "# output of the performance of the model\n",
        "avg_loss, avg_r2_score = model_loss(model, loader)\n",
        "print(\"The model's L1 loss is: \" + str(avg_loss))\n",
        "print(\"The model's R^2 score is: \" + str(avg_r2_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sGmaODwyRX7",
        "outputId": "f17ae8ca-dcee-41f1-be26-53465f9b2977"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model's L1 loss is: 123.86143341064454\n",
            "The model's R^2 score is: 0.7929343312377688\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(1,2,1)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.plot(np.arange(1,101),loss_list)\n",
        "plt.subplot(1,2,2)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('R2')\n",
        "plt.plot(np.arange(1,101), r2_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "Nf3w9_-Rycpt",
        "outputId": "e85788a2-ea44-4d7a-c548-e5026466ab4c"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}